name: Daily Martplus Scraper

on:
  schedule:
    - cron: '0 0 * * *'  # Runs daily at 00:00 UTC
  workflow_dispatch:     # Allows manual trigger

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    - name: ğŸ“¥ Checkout repo
      uses: actions/checkout@v3

    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: ğŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 pandas gspread python-dotenv

    - name: ğŸ” Create credentials.json from secret
      run: |
        printf "%s" "${{ secrets.GOOGLE_CREDS_JSON }}" > credentials_raw.json
        python -c "import json; open('credentials.json', 'w').write(json.dumps(json.loads(open('credentials_raw.json').read())))"

    - name: ğŸ•¸ï¸ Run scraper (scraper.py)
      run: python scraper.py

    - name: ğŸ“¤ Upload to Google Sheets (main.py)
      env:
        SPREADSHEET_ID: ${{ secrets.SPREADSHEET_ID }}
        SHEET_NAME: ${{ secrets.SHEET_NAME }}
      run: python main.py
